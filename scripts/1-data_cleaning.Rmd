---
title: "Data Cleaning"
author: "Heqing Sun"
date: "6/18/2020"
output: html_document
---

## Environment Setup
```{r}
# setwd('/Users/sun/Documents/GitHub/Terminix-Data-Challenge')
getwd()

# If this errors out, need to install packages
source('0-setup_environment.R')
```

## Access the cvs file
```{r}
data <- read.csv(file = '../data/raw/dataset.csv')
## 23651 obs, 46 vars
```

## Data Exploration
```{r}
summarizeColumns(data) %>%
  select(name,type,na,mean,median,min,max)%>%
  mutate(percent_miss=(na/nrow(data))*100)
## Maximum missing percentage is 16.4%
## There are four percentage columns ranging from 0 to 1000: MTA6200A_PCT, MTA7430_AVG, MTF6200A_PCT, MTF6280A_PCT

names(data[sapply(data, is.factor)])
## 5 categorical variables: CANCEL_REASON, CUSTOMER_CANCEL_REASON, IS_ELIGIBLE_FOR_EVERGREEN, Mosaic_Z4, REN220_SALES_CHANNEL
```

# Deal with four problematic pct variables
```{r}
# Plot histograms
m.data_problematic <- data %>% select(MTA6200A_PCT, MTA7430_AVG, MTF6200A_PCT, MTF6280A_PCT)

m.data_problematic %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram()

# Change their range to 1-100
data$MTA6200A_PCT <- data$MTA6200A_PCT/10
data$MTA7430_AVG <- data$MTA7430_AVG/10
data$MTF6200A_PCT <- data$MTF6200A_PCT/10
data$MTF6280A_PCT <- data$MTF6280A_PCT/10

data %>% select(MTA6200A_PCT, MTA7430_AVG, MTF6200A_PCT, MTF6280A_PCT) %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram()
```

## Deal with Categorical Variables
```{r}
count(data, 'CANCEL_REASON')  ## 24 levels
count(data, 'CUSTOMER_CANCEL_REASON')  ## 59 levels
count(data, 'IS_ELIGIBLE_FOR_EVERGREEN')  ## 2 levels
count(data, 'Mosaic_Z4')  ## 72 levels
count(data, 'REN220_SALES_CHANNEL')  ## 3 levels

# Replace N, Y with 0, 1 in IS_ELIGIBLE_FOR_EVERGREEN column
data$IS_ELIGIBLE_FOR_EVERGREEN <- gsub('N', 0, data$IS_ELIGIBLE_FOR_EVERGREEN)
data$IS_ELIGIBLE_FOR_EVERGREEN <- gsub('Y', 1, data$IS_ELIGIBLE_FOR_EVERGREEN)
data$IS_ELIGIBLE_FOR_EVERGREEN <- as.numeric(as.character(data$IS_ELIGIBLE_FOR_EVERGREEN))

# Use one-hot encoding for other categorical variables
m.data_1h <- one_hot(as.data.table(data))
## 23651 obs, 200 vars

# Check if any columns are non-numeric
m.data_1h %>% select_if(negate(is.numeric))
## 0 rows
```

## Deal with duplicates Ref1
```{r}
m.data_1h_dup <- m.data_1h[duplicated(m.data_1h$Ref1),] ## 27 duplicates

# Remove duplicated rows based on Ref1
m.data_1h_no_dup_Ref1 <- m.data_1h %>% distinct(Ref1, .keep_all = TRUE)

# Convert Ref1 - record key to the index
data_no_dup <- m.data_1h_no_dup_Ref1 %>%
     remove_rownames() %>%
     column_to_rownames(var = 'Ref1')
## 23624 obs, 199 vars
## data_1h_no_dup_Ref1: no dupliates in Ref1, but still some vars have exact same all other variables values except Ref1 - no worries right now

# Check if target variable is imbalanced
table(data_no_dup$sale)
## 5.4 : 1 imbalanced dataset

# Save to RDS
saveRDS(data_no_dup, '../data/clean/data_no_dup.rds')

# Clean up environment
rm(list = ls(pattern = "^m."))
```



