---
title: "Terminix Data Challenge"
author: "Heqing Sun"
date: "6/18/2020"
output: html_document
---

## Environment Setup
```{r}
setwd('/Users/sun/Documents/GitHub/Terminix-Data-Challenge')
# getwd()

library(tidyverse)
library(janitor)
library(magrittr)
library(mlr)
library(readxl)
library(rjson)
library(utils)
library(RCurl)
library(censusapi)
library(sf)
library(tigris)
library(devtools)
library(zeallot)
library(httr)
library(plyr)
library(jsonlite)
library(tigris)
library(corrplot)
library(DataExplorer)
library(naniar)
library(corrplot)
library(reshape2)
library(flexclust)
library(data.table)
library(mltools)
```

## Access the cvs file
```{r}
data <- read.csv(file = 'data/raw/dataset.csv')
## 23651 obs, 46 vars
```

## Data Exploration
```{r}
summarizeColumns(data) %>%
  select(name,type,na,mean,median,min,max)%>%
  mutate(percent_miss=(na/nrow(data))*100)
## Maximum missing percentage is 16.4%
## There are four percentage columns ranging from 0 to 1000: MTA6200A_PCT, MTA7430_AVG, MTF6200A_PCT, MTF6280A_PCT

names(data[sapply(data, is.factor)])
## 5 categorical variables: CANCEL_REASON, CUSTOMER_CANCEL_REASON, IS_ELIGIBLE_FOR_EVERGREEN, Mosaic_Z4, REN220_SALES_CHANNEL
```

## Plot histograms for four problematic pct variables
```{r}
data_problematic <- data %>% select(MTA6200A_PCT, MTA7430_AVG, MTF6200A_PCT, MTF6280A_PCT)

data_problematic %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram()
```

## Deal with Categorical Variables
```{r}
count(data, 'CANCEL_REASON')  ## 24 levels
count(data, 'CUSTOMER_CANCEL_REASON')  ## 59 levels
count(data, 'IS_ELIGIBLE_FOR_EVERGREEN')  ## 2 levels
count(data, 'Mosaic_Z4')  ## 72 levels
count(data, 'REN220_SALES_CHANNEL')  ## 3 levels

# Replace N, Y with 0, 1 in IS_ELIGIBLE_FOR_EVERGREEN column
data$IS_ELIGIBLE_FOR_EVERGREEN <- gsub('N', 0, data$IS_ELIGIBLE_FOR_EVERGREEN)
data$IS_ELIGIBLE_FOR_EVERGREEN <- gsub('Y', 1, data$IS_ELIGIBLE_FOR_EVERGREEN)
data$IS_ELIGIBLE_FOR_EVERGREEN <- as.numeric(as.character(data$IS_ELIGIBLE_FOR_EVERGREEN))

# Use one-hot encoding for other categorical variables
data_1h <- one_hot(as.data.table(data))
# names(data_1h)
## 23651 obs, 200 vars

# Check if any columns are non-numeric
data_1h %>% select_if(negate(is.numeric))
## 0 rows
```

## Deal with duplicates
```{r}
data_1h_dup <- data_1h[duplicated(data_1h$Ref1),]

# get all duplicated obs
data_1h_dup_Ref1 <- data_1h_dup$Ref1
dupe <- data_1h[is.element(data_1h$Ref1, data_1h_dup_Ref1),]
## 46 obs in total, and 19 of them are unique Ref1.
## But some of them have different Ref1, all other variables are the same.

# Remove duplicated rows based on Ref1
data_1h_no_dup_Ref1 <- data_1h %>% distinct(Ref1, .keep_all = TRUE)

# Convert Ref1 - record key to the index
data_1h_no_dup_Ref1 <- data_1h_no_dup_Ref1 %>%
     remove_rownames() %>%
     column_to_rownames(var = 'Ref1')
## 23624 obs, 199 vars
## data_1h_no_dup_Ref1: no dupliates in Ref1, but still some vars have exact same all other variables values except Ref1
```

## Data Partitioning - Split training and validation sets
```{r}
smp_size <- floor(0.75 * nrow(data_1h_no_dup_Ref1))

# set the seed to make the partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data_1h_no_dup_Ref1)), size = smp_size)

train <- data_1h_no_dup_Ref1[train_ind, ]
test <- data_1h_no_dup_Ref1[-train_ind, ]

X_train <- train %>% select (-sale)
X_test <- test %>% select (-sale)
y_train <- train %>% select (sale)
y_test <- test %>% select (sale)
```

## Pre-processing the data
```{r}
# Use complete cases for feature selection
train_cc <- train %>%
  filter(complete.cases(.)) 

summarizeColumns(train_cc) %>%
  select(name,type,na,mean,median,min,max)%>%
  mutate(percent_miss=(na/nrow(train_cc))*100)
## No missing values, but some variables are all 0 at this complete case scenario

# Remove columns that are all 0s
train_cc_no0 <- train_cc[, colSums(train_cc != 0) > 0]
```

## Boruta
```{r}
# Perform Boruta search
library(Boruta)
boruta_output <- Boruta(sale ~ ., data=na.omit(train), doTrace=0)  

# Get significant variables including tentatives
boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)
print(boruta_signif)
## 58 variables are selected
```

```{r}
# Do a tentative rough fix
roughFixMod <- TentativeRoughFix(boruta_output)
boruta_signif <- getSelectedAttributes(roughFixMod)
print(boruta_signif)
## 52 variables are selected
```

```{r}
# Variable Importance Scores
imps <- attStats(roughFixMod)
imps2 = imps[imps$decision != 'Rejected', c('meanImp', 'decision')]
boruta_df <- head(imps2[order(-imps2$meanImp), ], 10)  # descending sort
boruta_vars <- row.names(boruta_df)
print(boruta_vars)
# [1] "CUSTOMER_CANCEL_REASON_OTHER" "BASE_PRICE"                   "BCC5520_AVG"
# [4] "ILN6200A_PCT"                 "REV7430_AVG"                  "OPTIONS_PRICE"
# [7] "BCC5421_AVG"                  "ALL6200A_PCT"                 "ALL6280A_PCT"
# [10] "ILN7430_AVG"

# Plot variable importance
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")  
```

## Variable Importance from Machine Learning Algorithms - super fast
```{r}
# Train an rpart model and compute variable importance.
library(caret)
set.seed(100)
# colnames(train) <- make.names(colnames(train))

# Convert target variable to the factor
train$sale = as.factor(train$sale)
rPartMod <- train(sale ~ ., data=na.omit(train), method="rpart")
rpartImp <- varImp(rPartMod)
print(rpartImp)
# CUSTOMER_CANCEL_REASON_OTHER	BASE_PRICE		OPTIONS_PRICE
# REN220_SALES_CHANNEL_DTC.NON.TPV		EN220_SALES_CHANNEL_DTC.TPV
## Only 5 variables have feature importance greater than 0.
```

## Regularized Random Forest (RRF) algorithm - took too long, did not run it successfully
```{r}
# Train an RRF model and compute variable importance.
set.seed(100)
rrfMod <- train(sale ~ ., data=na.omit(train), method="RRF")

rrfImp <- varImp(rrfMod, scale=F)
rrfImp

plot(rrfImp, top = 20, main='Variable Importance')
```

## Subest Data Partitioning - Split training and validation sets (only 10 features)
```{r}
smp_size <- floor(0.75 * nrow(data_1h_no_dup_Ref1))

# set the seed to make the partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data_1h_no_dup_Ref1)), size = smp_size)

data_1h_no_dup_Ref1_sub_withTarget <- data_1h_no_dup_Ref1 %>% select(sale, all_of(boruta_vars))
data_1h_no_dup_Ref1_sub <- data_1h_no_dup_Ref1 %>% select(all_of(boruta_vars))

train <- data_1h_no_dup_Ref1_sub_withTarget[train_ind, ]
test <- data_1h_no_dup_Ref1_sub_withTarget[-train_ind, ]

X_train <- train %>% select (-sale)
X_test <- test %>% select (-sale)
y_train <- train %>% select (sale)
y_test <- test %>% select (sale)
```

## Add Missing Value Indicator
```{r}
summarizeColumns(data_1h_no_dup_Ref1_sub) %>%
  select(name,type,na,mean,median,min,max)%>%
  mutate(percent_miss=(na/nrow(train_sub))*100)

# Create missing indicators, but some of them will be all 0
for (var in names(data_1h_no_dup_Ref1_sub)) {
    data_1h_no_dup_Ref1_sub[[paste0(var, "_missing")]] <- ifelse(is.na(data_1h_no_dup_Ref1_sub[[var]]), 1, 0)
  }

# Filter missing indicators
x.missing_indicators <- data_1h_no_dup_Ref1_sub %>% 
  select(ends_with("_missing"))

# Filter non-zero missing indicators
x.missing_indicators_non_0 = x.missing_indicators[colSums(Filter(is.numeric, x.missing_indicators)) != 0]
names(x.missing_indicators_non_0)
all(x.missing_indicators_non_0$BCC5520_AVG_missing == x.missing_indicators_non_0$ILN6200A_PCT_missing)
all(x.missing_indicators_non_0$BCC5520_AVG_missing == x.missing_indicators_non_0$REV7430_AVG_missing)
all(x.missing_indicators_non_0$BCC5520_AVG_missing == x.missing_indicators_non_0$BCC5421_AVG_missing)
all(x.missing_indicators_non_0$BCC5520_AVG_missing == x.missing_indicators_non_0$ALL6200A_PCT_missing)
all(x.missing_indicators_non_0$BCC5520_AVG_missing == x.missing_indicators_non_0$ALL6280A_PCT_missing)
all(x.missing_indicators_non_0$BCC5520_AVG_missing == x.missing_indicators_non_0$ILN7430_AVG_missing)
## These seven indicators have the exact same distribution, so only need one to represent all other 6

x.missing_indicators_meaningful <- x.missing_indicators_non_0 %>% select(BCC5520_AVG_missing, OPTIONS_PRICE_missing)

# Combine the original non-imputed data with the non-zero missing indicators
data_1h_no_dup_Ref1_sub <- data_1h_no_dup_Ref1 %>% select(all_of(boruta_vars))

data_1h_no_dup_Ref1_sub_withmi <- cbind(data_1h_no_dup_Ref1_sub, x.missing_indicators_meaningful)
```

## Imputing the NA using the MICE method
```{r}
# Split train test data
train_sub <- data_1h_no_dup_Ref1_sub_withmi[train_ind, ]
test_sub <- data_1h_no_dup_Ref1_sub_withmi[-train_ind, ]
library(mice)
x.train_sub_imputed <- mice(data=train_sub, m=5, method="cart", maxit=10, where = is.na(train_sub))

# picking one of the inerations to be work on
x.train_completeData <- complete(x.train_sub_imputed,5)

# check if still NAs after the imputation
sum(is.na(x.train_completeData)) ## 0
```

## Logistic regression model
```{r}
train_complete_withTarget <- merge(y_train ,x.train_completeData)

Log1 = glm(sale~., data = x.train_completeData, family = binomial)
summary(TitanicLog1)

```


## Check Multicollinearity
```{r}

```



## Correlation Matrix
```{r}
x.res <- cor(train_sub[sapply(train_sub, is.numeric)], use='pairwise')

corrplot(x.res, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```



```{r}
# Remove redudant features
set.seed(7)
# load the library
library(mlbench)
library(caret)

# calculate correlation matrix
correlationMatrix <- cor(X_train_1h_cc_no0[,])
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
# print indexes of highly correlated attributes
print(highlyCorrelated)

```




